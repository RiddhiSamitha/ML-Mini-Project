{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fSOiz7Jw5UP",
        "outputId": "800ff7f7-f18b-4380-f82a-5fdb92f62e4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STREAMFLOW DISCHARGE FORECASTING - FIXED IMPLEMENTATION\n",
            "================================================================================\n",
            "Based on: Xiao & You (Stanford University)\n",
            "Models: Standard Feed-Forward NN and LSTM\n",
            "Fixes Applied:\n",
            "  ‚úì Removed early stopping - full 200 epochs training\n",
            "  ‚úì Using SGD optimizer (not Adam) for Standard NN\n",
            "  ‚úì Proper best model selection based on validation RMSE\n",
            "  ‚úì Correct activation functions (sigmoid for hidden, linear for output)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# For Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"STREAMFLOW DISCHARGE FORECASTING - FIXED IMPLEMENTATION\")\n",
        "print(\"=\"*80)\n",
        "print(\"Based on: Xiao & You (Stanford University)\")\n",
        "print(\"Models: Standard Feed-Forward NN and LSTM\")\n",
        "print(\"Fixes Applied:\")\n",
        "print(\"  ‚úì Removed early stopping - full 200 epochs training\")\n",
        "print(\"  ‚úì Using SGD optimizer (not Adam) for Standard NN\")\n",
        "print(\"  ‚úì Proper best model selection based on validation RMSE\")\n",
        "print(\"  ‚úì Correct activation functions (sigmoid for hidden, linear for output)\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJykDJXAxcxw",
        "outputId": "873970f3-460f-4771-8de7-f02dbe8737a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 1: Loading Dataset...\n",
            "============================================================\n",
            "\n",
            "First few rows of dataset:\n",
            "     datetime  PRECTOTCORR_z  discharge_cfs_z  discharge_cfs_z_lag1  \\\n",
            "0  01-01-2003      -0.394675         1.265288              1.265288   \n",
            "1  02-01-2003      -0.427561         1.485855              1.265288   \n",
            "2  03-01-2003      -0.458099         1.394400              1.485855   \n",
            "3  04-01-2003      -0.458099         0.791876              1.394400   \n",
            "4  05-01-2003      -0.453401         0.173212              0.791876   \n",
            "\n",
            "   discharge_cfs_z_lag2  discharge_cfs_z_lag3  discharge_cfs_z_lag4  \\\n",
            "0              1.265288              1.265288              1.265288   \n",
            "1              1.265288              1.265288              1.265288   \n",
            "2              1.265288              1.265288              1.265288   \n",
            "3              1.485855              1.265288              1.265288   \n",
            "4              1.394400              1.485855              1.265288   \n",
            "\n",
            "   discharge_cfs_z_lag5  PRECTOTCORR_z_lag1  PRECTOTCORR_z_lag2  \\\n",
            "0              1.265288           -0.394675           -0.394675   \n",
            "1              1.265288           -0.394675           -0.394675   \n",
            "2              1.265288           -0.427561           -0.394675   \n",
            "3              1.265288           -0.458099           -0.427561   \n",
            "4              1.265288           -0.458099           -0.458099   \n",
            "\n",
            "   PRECTOTCORR_z_lag3  PRECTOTCORR_z_lag4  PRECTOTCORR_z_lag5  \\\n",
            "0           -0.394675           -0.394675           -0.394675   \n",
            "1           -0.394675           -0.394675           -0.394675   \n",
            "2           -0.394675           -0.394675           -0.394675   \n",
            "3           -0.394675           -0.394675           -0.394675   \n",
            "4           -0.427561           -0.394675           -0.394675   \n",
            "\n",
            "   PRECTOTCORR_z_lag6  PRECTOTCORR_z_lag7  \n",
            "0           -0.394675           -0.394675  \n",
            "1           -0.394675           -0.394675  \n",
            "2           -0.394675           -0.394675  \n",
            "3           -0.394675           -0.394675  \n",
            "4           -0.394675           -0.394675  \n",
            "Warning: 2213 datetime values couldn't be parsed\n",
            "\n",
            "Checking for missing values...\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'PRECTOTCORR'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'PRECTOTCORR'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Remove missing values\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mChecking for missing values...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Missing in PRECTOTCORR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPRECTOTCORR\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.isna().sum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Missing in discharge_cfs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mdischarge_cfs\u001b[39m\u001b[33m'\u001b[39m].isna().sum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m df = df.dropna(subset=[\u001b[33m'\u001b[39m\u001b[33mPRECTOTCORR\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdischarge_cfs\u001b[39m\u001b[33m'\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
            "\u001b[31mKeyError\u001b[39m: 'PRECTOTCORR'"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 1: Loading Dataset...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "df = pd.read_csv(\"dataset_with_combined_lags.csv\")\n",
        "\n",
        "print(\"\\nFirst few rows of dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Convert datetime\n",
        "df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
        "\n",
        "if df['datetime'].isna().any():\n",
        "    print(f\"Warning: {df['datetime'].isna().sum()} datetime values couldn't be parsed\")\n",
        "    df = df.dropna(subset=['datetime'])\n",
        "\n",
        "# Remove missing values\n",
        "print(f\"\\nChecking for missing values...\")\n",
        "print(f\"  Missing in PRECTOTCORR: {df['PRECTOTCORR'].isna().sum()}\")\n",
        "print(f\"  Missing in discharge_cfs: {df['discharge_cfs'].isna().sum()}\")\n",
        "\n",
        "df = df.dropna(subset=['PRECTOTCORR', 'discharge_cfs'])\n",
        "\n",
        "print(f\"\\n‚úì Dataset loaded successfully\")\n",
        "print(f\"  Shape: {df.shape}\")\n",
        "print(f\"  Time period: {df['datetime'].min()} to {df['datetime'].max()}\")\n",
        "print(f\"  Total days: {len(df)}\")\n",
        "\n",
        "print(f\"\\nData Statistics:\")\n",
        "print(f\"  Precipitation (PRECTOTCORR):\")\n",
        "print(f\"    Min: {df['PRECTOTCORR'].min():.2f}, Max: {df['PRECTOTCORR'].max():.2f}\")\n",
        "print(f\"    Mean: {df['PRECTOTCORR'].mean():.2f}, Std: {df['PRECTOTCORR'].std():.2f}\")\n",
        "print(f\"  Discharge (discharge_cfs):\")\n",
        "print(f\"    Min: {df['discharge_cfs'].min():.2f}, Max: {df['discharge_cfs'].max():.2f}\")\n",
        "print(f\"    Mean: {df['discharge_cfs'].mean():.2f}, Std: {df['discharge_cfs'].std():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxkiyYVYx1Mo",
        "outputId": "2eff95d3-0085-4643-da69-2ae0ea6dff13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 2: Data Normalization (by Maximum Value)...\n",
            "============================================================\n",
            "‚úì Precipitation max: 86.1700\n",
            "‚úì Discharge max: 29700.00 ft¬≥/s\n",
            "‚úì Data normalized to [0, 1] range\n",
            "\n",
            "üìå Paper uses: Rainfall max = 6.8 inch, Discharge max = 29700 ft¬≥/s\n",
            "üìå Your data: Check if values are comparable\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2: Data Normalization (by Maximum Value)...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "precipitation = df['PRECTOTCORR'].values\n",
        "discharge = df['discharge_cfs'].values\n",
        "\n",
        "# Normalize by maximum value (as per paper)\n",
        "precip_max = precipitation.max()\n",
        "discharge_max = discharge.max()\n",
        "\n",
        "precip_normalized = precipitation / precip_max\n",
        "discharge_normalized = discharge / discharge_max\n",
        "\n",
        "print(f\"‚úì Precipitation max: {precip_max:.4f}\")\n",
        "print(f\"‚úì Discharge max: {discharge_max:.2f} ft¬≥/s\")\n",
        "print(f\"‚úì Data normalized to [0, 1] range\")\n",
        "print(f\"\\nüìå Paper uses: Rainfall max = 6.8 inch, Discharge max = 29700 ft¬≥/s\")\n",
        "print(f\"üìå Your data: Check if values are comparable\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K5mZldfx7Lw",
        "outputId": "390e521f-5019-4d67-f5f9-7527d4bc76ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 3: Creating Lagged Features...\n",
            "============================================================\n",
            "‚úì Standard NN lag combinations: 12\n",
            "‚úì LSTM lag combinations: 6\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 3: Creating Lagged Features...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def create_lagged_features(precip, discharge, lag_precip, lag_discharge):\n",
        "    \"\"\"\n",
        "    Create lagged features: Q(t) = f{R(t-1),...,R(t-m), Q(t-1),...,Q(t-n)}\n",
        "    \"\"\"\n",
        "    n_samples = len(precip)\n",
        "    max_lag = max(lag_precip, lag_discharge)\n",
        "\n",
        "    n_features = lag_precip + lag_discharge\n",
        "    X = np.zeros((n_samples - max_lag, n_features))\n",
        "    y = np.zeros(n_samples - max_lag)\n",
        "\n",
        "    for i in range(max_lag, n_samples):\n",
        "        # Lagged precipitation: R(t-1), R(t-2), ..., R(t-m)\n",
        "        precip_features = [precip[i-j] for j in range(1, lag_precip + 1)]\n",
        "\n",
        "        # Lagged discharge: Q(t-1), Q(t-2), ..., Q(t-n)\n",
        "        discharge_features = [discharge[i-j] for j in range(1, lag_discharge + 1)]\n",
        "\n",
        "        # Combine features\n",
        "        X[i - max_lag, :] = precip_features + discharge_features\n",
        "\n",
        "        # Target: Q(t)\n",
        "        y[i - max_lag] = discharge[i]\n",
        "\n",
        "    valid_indices = np.arange(max_lag, n_samples)\n",
        "    return X, y, valid_indices\n",
        "\n",
        "# Define lag combinations (as per paper)\n",
        "lag_combinations_standard = [\n",
        "    (2,3), (3,4), (4,5), (5,6), (6,7),  # n-m=1\n",
        "    (2,4), (3,5), (4,6), (5,7),         # n-m=2\n",
        "    (2,5), (3,6), (4,7),                # n-m=3\n",
        "]\n",
        "\n",
        "lag_combinations_lstm = [(i,i) for i in range(2,8)]  # m=n for LSTM\n",
        "\n",
        "print(f\"‚úì Standard NN lag combinations: {len(lag_combinations_standard)}\")\n",
        "print(f\"‚úì LSTM lag combinations: {len(lag_combinations_lstm)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78Pd8ZTRyA3v",
        "outputId": "6469336e-7b5e-4f9d-bb0e-b393d0b42201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 4: Temporal Train-Test Split...\n",
            "============================================================\n",
            "‚úì Train ratio: 80%\n",
            "‚úì Using temporal split (paper: 2003-2007 train, 2008-2012 validation)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 4: Temporal Train-Test Split...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "train_ratio = 0.8\n",
        "\n",
        "def split_data(X, y, valid_indices, train_ratio=0.8):\n",
        "    \"\"\"Split data temporally (chronological order preserved)\"\"\"\n",
        "    split_idx = int(len(X) * train_ratio)\n",
        "\n",
        "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "    train_indices = valid_indices[:split_idx]\n",
        "    test_indices = valid_indices[split_idx:]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, train_indices, test_indices\n",
        "\n",
        "print(f\"‚úì Train ratio: {train_ratio*100:.0f}%\")\n",
        "print(f\"‚úì Using temporal split (paper: 2003-2007 train, 2008-2012 validation)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02gxn_LlyGqE",
        "outputId": "36e449fa-982f-4032-fdc6-313858eb2f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 5: Building Neural Network Models...\n",
            "============================================================\n",
            "‚úì Standard NN: Input ‚Üí Hidden(sigmoid) ‚Üí Output(linear)\n",
            "‚úì LSTM: Input ‚Üí LSTM ‚Üí Output(linear)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 5: Building Neural Network Models...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def build_standard_nn(input_size, hidden_size=12):\n",
        "    \"\"\"\n",
        "    Standard Feed-Forward Neural Network (3-layer)\n",
        "    - Hidden layer: SIGMOID activation (as per paper)\n",
        "    - Output layer: LINEAR (no activation, as per paper)\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(hidden_size, activation='sigmoid', input_shape=(input_size,)),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_lstm_model(sequence_length, hidden_size=12):\n",
        "    \"\"\"\n",
        "    LSTM Model (3-layer)\n",
        "    - LSTM layer with specified hidden size\n",
        "    - Output: dense linear\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        LSTM(hidden_size, input_shape=(sequence_length, 2), return_sequences=False),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "print(\"‚úì Standard NN: Input ‚Üí Hidden(sigmoid) ‚Üí Output(linear)\")\n",
        "print(\"‚úì LSTM: Input ‚Üí LSTM ‚Üí Output(linear)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E44ysQZyLTS",
        "outputId": "b2605a9f-36da-4817-d525-717be8ad021f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 6: Hyperparameter Search & Model Training...\n",
            "============================================================\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training Standard Feed-Forward Neural Networks...\n",
            "------------------------------------------------------------\n",
            "Key changes from previous version:\n",
            "  ‚Ä¢ Using SGD optimizer (lr=0.009) instead of Adam\n",
            "  ‚Ä¢ Training for FULL 200 epochs (no early stopping)\n",
            "  ‚Ä¢ Saving best model based on validation loss (.keras format)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Lag config: m=2, n=3\n",
            "  [1/84] Hidden=4 ‚Üí RMSE: 5.20%\n",
            "  [2/84] Hidden=8 ‚Üí RMSE: 6.06%\n",
            "  [3/84] Hidden=12 ‚Üí RMSE: 5.35%\n",
            "  [4/84] Hidden=16 ‚Üí RMSE: 5.00%\n",
            "  [5/84] Hidden=20 ‚Üí RMSE: 4.21%\n",
            "  [6/84] Hidden=24 ‚Üí RMSE: 5.48%\n",
            "  [7/84] Hidden=28 ‚Üí RMSE: 5.29%\n",
            "\n",
            "Lag config: m=3, n=4\n",
            "  [8/84] Hidden=4 ‚Üí RMSE: 6.40%\n",
            "  [9/84] Hidden=8 ‚Üí RMSE: 5.55%\n",
            "  [10/84] Hidden=12 ‚Üí RMSE: 5.61%\n",
            "  [11/84] Hidden=16 ‚Üí RMSE: 5.15%\n",
            "  [12/84] Hidden=20 ‚Üí RMSE: 4.91%\n",
            "  [13/84] Hidden=24 ‚Üí RMSE: 4.88%\n",
            "  [14/84] Hidden=28 ‚Üí RMSE: 4.69%\n",
            "\n",
            "Lag config: m=4, n=5\n",
            "  [15/84] Hidden=4 ‚Üí RMSE: 5.45%\n",
            "  [16/84] Hidden=8 ‚Üí RMSE: 5.57%\n",
            "  [17/84] Hidden=12 ‚Üí RMSE: 4.31%\n",
            "  [18/84] Hidden=16 ‚Üí RMSE: 5.08%\n",
            "  [19/84] Hidden=20 ‚Üí RMSE: 5.07%\n",
            "  [20/84] Hidden=24 ‚Üí RMSE: 5.18%\n",
            "  [21/84] Hidden=28 ‚Üí RMSE: 4.91%\n",
            "\n",
            "Lag config: m=5, n=6\n",
            "  [22/84] Hidden=4 ‚Üí RMSE: 4.72%\n",
            "  [23/84] Hidden=8 ‚Üí RMSE: 5.59%\n",
            "  [24/84] Hidden=12 ‚Üí RMSE: 5.78%\n",
            "  [25/84] Hidden=16 ‚Üí RMSE: 4.96%\n",
            "  [26/84] Hidden=20 ‚Üí RMSE: 5.85%\n",
            "  [27/84] Hidden=24 ‚Üí RMSE: 5.92%\n",
            "  [28/84] Hidden=28 ‚Üí RMSE: 4.78%\n",
            "\n",
            "Lag config: m=6, n=7\n",
            "  [29/84] Hidden=4 ‚Üí RMSE: 5.73%\n",
            "  [30/84] Hidden=8 ‚Üí RMSE: 5.02%\n",
            "  [31/84] Hidden=12 ‚Üí RMSE: 4.76%\n",
            "  [32/84] Hidden=16 ‚Üí RMSE: 5.92%\n",
            "  [33/84] Hidden=20 ‚Üí RMSE: 6.51%\n",
            "  [34/84] Hidden=24 ‚Üí RMSE: 5.92%\n",
            "  [35/84] Hidden=28 ‚Üí RMSE: 4.92%\n",
            "\n",
            "Lag config: m=2, n=4\n",
            "  [36/84] Hidden=4 ‚Üí RMSE: 6.20%\n",
            "  [37/84] Hidden=8 ‚Üí RMSE: 6.06%\n",
            "  [38/84] Hidden=12 ‚Üí RMSE: 4.61%\n",
            "  [39/84] Hidden=16 ‚Üí RMSE: 5.16%\n",
            "  [40/84] Hidden=20 ‚Üí RMSE: 6.27%\n",
            "  [41/84] Hidden=24 ‚Üí RMSE: 5.06%\n",
            "  [42/84] Hidden=28 ‚Üí RMSE: 4.61%\n",
            "\n",
            "Lag config: m=3, n=5\n",
            "  [43/84] Hidden=4 ‚Üí RMSE: 4.82%\n",
            "  [44/84] Hidden=8 ‚Üí RMSE: 5.85%\n",
            "  [45/84] Hidden=12 ‚Üí RMSE: 6.14%\n",
            "  [46/84] Hidden=16 ‚Üí RMSE: 5.53%\n",
            "  [47/84] Hidden=20 ‚Üí RMSE: 5.55%\n",
            "  [48/84] Hidden=24 ‚Üí RMSE: 4.80%\n",
            "  [49/84] Hidden=28 ‚Üí RMSE: 5.40%\n",
            "\n",
            "Lag config: m=4, n=6\n",
            "  [50/84] Hidden=4 ‚Üí RMSE: 5.14%\n",
            "  [51/84] Hidden=8 ‚Üí RMSE: 5.50%\n",
            "  [52/84] Hidden=12 ‚Üí RMSE: 4.34%\n",
            "  [53/84] Hidden=16 ‚Üí RMSE: 5.29%\n",
            "  [54/84] Hidden=20 ‚Üí RMSE: 4.92%\n",
            "  [55/84] Hidden=24 ‚Üí RMSE: 5.07%\n",
            "  [56/84] Hidden=28 ‚Üí RMSE: 4.61%\n",
            "\n",
            "Lag config: m=5, n=7\n",
            "  [57/84] Hidden=4 ‚Üí RMSE: 5.80%\n",
            "  [58/84] Hidden=8 ‚Üí RMSE: 6.61%\n",
            "  [59/84] Hidden=12 ‚Üí RMSE: 5.02%\n",
            "  [60/84] Hidden=16 ‚Üí RMSE: 5.32%\n",
            "  [61/84] Hidden=20 ‚Üí RMSE: 4.51%\n",
            "  [62/84] Hidden=24 ‚Üí RMSE: 5.14%\n",
            "  [63/84] Hidden=28 ‚Üí RMSE: 5.80%\n",
            "\n",
            "Lag config: m=2, n=5\n",
            "  [64/84] Hidden=4 ‚Üí RMSE: 5.13%\n",
            "  [65/84] Hidden=8 ‚Üí RMSE: 5.91%\n",
            "  [66/84] Hidden=12 ‚Üí RMSE: 5.85%\n",
            "  [67/84] Hidden=16 ‚Üí RMSE: 5.00%\n",
            "  [68/84] Hidden=20 ‚Üí RMSE: 6.23%\n",
            "  [69/84] Hidden=24 ‚Üí RMSE: 4.99%\n",
            "  [70/84] Hidden=28 ‚Üí RMSE: 5.21%\n",
            "\n",
            "Lag config: m=3, n=6\n",
            "  [71/84] Hidden=4 ‚Üí RMSE: 7.00%\n",
            "  [72/84] Hidden=8 ‚Üí RMSE: 5.57%\n",
            "  [73/84] Hidden=12 ‚Üí RMSE: 5.64%\n",
            "  [74/84] Hidden=16 ‚Üí RMSE: 5.16%\n",
            "  [75/84] Hidden=20 ‚Üí RMSE: 4.88%\n",
            "  [76/84] Hidden=24 ‚Üí RMSE: 4.97%\n",
            "  [77/84] Hidden=28 ‚Üí RMSE: 5.60%\n",
            "\n",
            "Lag config: m=4, n=7\n",
            "  [78/84] Hidden=4 ‚Üí RMSE: 6.13%\n",
            "  [79/84] Hidden=8 ‚Üí RMSE: 6.26%\n",
            "  [80/84] Hidden=12 ‚Üí RMSE: 5.81%\n",
            "  [81/84] Hidden=16 ‚Üí RMSE: 5.47%\n",
            "  [82/84] Hidden=20 ‚Üí RMSE: 5.17%\n",
            "  [83/84] Hidden=24 ‚Üí RMSE: 6.46%\n",
            "  [84/84] Hidden=28 ‚Üí RMSE: 6.03%\n",
            "\n",
            "------------------------------------------------------------\n",
            "Training LSTM Models...\n",
            "------------------------------------------------------------\n",
            "Key changes:\n",
            "  ‚Ä¢ Using Adam optimizer (lr=0.001) as per paper for LSTM\n",
            "  ‚Ä¢ Training for FULL 200 epochs\n",
            "  ‚Ä¢ Using .keras format to avoid warnings\n",
            "------------------------------------------------------------\n",
            "\n",
            "Lag config: m=n=2\n",
            "  [1/42] Hidden=4 ‚Üí RMSE: 3.01%\n",
            "  [2/42] Hidden=8 ‚Üí RMSE: 3.23%\n",
            "  [3/42] Hidden=12 ‚Üí RMSE: 3.05%\n",
            "  [4/42] Hidden=16 ‚Üí RMSE: 3.28%\n",
            "  [5/42] Hidden=20 ‚Üí RMSE: 3.23%\n",
            "  [6/42] Hidden=24 ‚Üí RMSE: 3.16%\n",
            "  [7/42] Hidden=28 ‚Üí RMSE: 3.25%\n",
            "\n",
            "Lag config: m=n=3\n",
            "  [8/42] Hidden=4 ‚Üí RMSE: 2.79%\n",
            "  [9/42] Hidden=8 ‚Üí RMSE: 3.16%\n",
            "  [10/42] Hidden=12 ‚Üí RMSE: 2.94%\n",
            "  [11/42] Hidden=16 ‚Üí RMSE: 2.99%\n",
            "  [12/42] Hidden=20 ‚Üí RMSE: 2.92%\n",
            "  [13/42] Hidden=24 ‚Üí RMSE: 2.92%\n",
            "  [14/42] Hidden=28 ‚Üí RMSE: 2.90%\n",
            "\n",
            "Lag config: m=n=4\n",
            "  [15/42] Hidden=4 ‚Üí RMSE: 3.00%\n",
            "  [16/42] Hidden=8 ‚Üí RMSE: 3.25%\n",
            "  [17/42] Hidden=12 ‚Üí RMSE: 3.14%\n",
            "  [18/42] Hidden=16 ‚Üí RMSE: 3.02%\n",
            "  [19/42] Hidden=20 ‚Üí RMSE: 3.09%\n",
            "  [20/42] Hidden=24 ‚Üí RMSE: 2.99%\n",
            "  [21/42] Hidden=28 ‚Üí RMSE: 3.04%\n",
            "\n",
            "Lag config: m=n=5\n",
            "  [22/42] Hidden=4 ‚Üí RMSE: 3.04%\n",
            "  [23/42] Hidden=8 ‚Üí RMSE: 3.14%\n",
            "  [24/42] Hidden=12 ‚Üí RMSE: 3.23%\n",
            "  [25/42] Hidden=16 ‚Üí RMSE: 3.15%\n",
            "  [26/42] Hidden=20 ‚Üí RMSE: 3.17%\n",
            "  [27/42] Hidden=24 ‚Üí RMSE: 3.15%\n",
            "  [28/42] Hidden=28 ‚Üí RMSE: 2.99%\n",
            "\n",
            "Lag config: m=n=6\n",
            "  [29/42] Hidden=4 ‚Üí RMSE: 2.99%\n",
            "  [30/42] Hidden=8 ‚Üí RMSE: 3.09%\n",
            "  [31/42] Hidden=12 ‚Üí RMSE: 3.16%\n",
            "  [32/42] Hidden=16 ‚Üí RMSE: 3.04%\n",
            "  [33/42] Hidden=20 ‚Üí RMSE: 3.10%\n",
            "  [34/42] Hidden=24 ‚Üí RMSE: 3.08%\n",
            "  [35/42] Hidden=28 ‚Üí RMSE: 3.04%\n",
            "\n",
            "Lag config: m=n=7\n",
            "  [36/42] Hidden=4 ‚Üí RMSE: 3.14%\n",
            "  [37/42] Hidden=8 ‚Üí RMSE: 2.96%\n",
            "  [38/42] Hidden=12 ‚Üí RMSE: 3.05%\n",
            "  [39/42] Hidden=16 ‚Üí RMSE: 3.06%\n",
            "  [40/42] Hidden=20 ‚Üí RMSE: 3.18%\n",
            "  [41/42] Hidden=24 ‚Üí RMSE: 3.21%\n",
            "  [42/42] Hidden=28 ‚Üí RMSE: 3.07%\n",
            "\n",
            "============================================================\n",
            "BEST MODELS FOUND\n",
            "============================================================\n",
            "\n",
            "üèÜ Best Standard NN:\n",
            "   Lag Precip (m): 2\n",
            "   Lag Discharge (n): 3\n",
            "   Hidden Size: 20\n",
            "   Overall RMSE: 4.21%\n",
            "   Peak RMSE: 10.26%\n",
            "   Non-Peak RMSE: 1.78%\n",
            "   R¬≤ Score: 0.5377\n",
            "   Best Epoch: 200\n",
            "\n",
            "üèÜ Best LSTM:\n",
            "   Lag (m=n): 3\n",
            "   Hidden Size: 4\n",
            "   Overall RMSE: 2.79%\n",
            "   Peak RMSE: 6.88%\n",
            "   Non-Peak RMSE: 1.10%\n",
            "   R¬≤ Score: 0.7971\n",
            "   Best Epoch: 141\n",
            "\n",
            "üìä Paper's Best Results for Comparison:\n",
            "   Standard NN: Overall=0.23%, Peak=0.63%, Non-Peak=0.07%\n",
            "   LSTM: Overall=2.43%, Peak=6.78%, Non-Peak=0.54%\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 6: Hyperparameter Search & Model Training...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results_standard = []\n",
        "results_lstm = []\n",
        "\n",
        "hidden_sizes = [4, 8, 12, 16, 20, 24, 28]\n",
        "\n",
        "# Create temp directory for model checkpoints\n",
        "os.makedirs('temp_models', exist_ok=True)\n",
        "\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"Training Standard Feed-Forward Neural Networks...\")\n",
        "print(\"-\"*60)\n",
        "print(\"Key changes from previous version:\")\n",
        "print(\"  ‚Ä¢ Using SGD optimizer (lr=0.009) instead of Adam\")\n",
        "print(\"  ‚Ä¢ Training for FULL 200 epochs (no early stopping)\")\n",
        "print(\"  ‚Ä¢ Saving best model based on validation loss (.keras format)\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "model_count = 0\n",
        "total_models_standard = len(lag_combinations_standard) * len(hidden_sizes)\n",
        "\n",
        "for lag_precip, lag_discharge in lag_combinations_standard:\n",
        "    print(f\"\\nLag config: m={lag_precip}, n={lag_discharge}\")\n",
        "\n",
        "    # Create features\n",
        "    X, y, valid_indices = create_lagged_features(\n",
        "        precip_normalized, discharge_normalized,\n",
        "        lag_precip, lag_discharge\n",
        "    )\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test, train_idx, test_idx = split_data(\n",
        "        X, y, valid_indices, train_ratio\n",
        "    )\n",
        "\n",
        "    input_size = X_train.shape[1]\n",
        "\n",
        "    for hidden_size in hidden_sizes:\n",
        "        model_count += 1\n",
        "        print(f\"  [{model_count}/{total_models_standard}] Hidden={hidden_size}\", end=\" \", flush=True)\n",
        "\n",
        "        # Build model\n",
        "        model = build_standard_nn(input_size, hidden_size)\n",
        "\n",
        "        # FIXED: Using SGD with learning rate 0.009 (as per paper)\n",
        "        model.compile(\n",
        "            optimizer=SGD(learning_rate=0.009, momentum=0.0),\n",
        "            loss='mse',\n",
        "            metrics=['mae']\n",
        "        )\n",
        "\n",
        "        # Save best model checkpoint (using .keras format to avoid warnings)\n",
        "        checkpoint_path = f'temp_models/standard_m{lag_precip}_n{lag_discharge}_h{hidden_size}.keras'\n",
        "        checkpoint = ModelCheckpoint(\n",
        "            checkpoint_path,\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            mode='min',\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # FIXED: Train for FULL 200 epochs without early stopping\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_test, y_test),\n",
        "            epochs=200,\n",
        "            batch_size=32,\n",
        "            callbacks=[checkpoint],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Load best model\n",
        "        try:\n",
        "            best_model = keras.models.load_model(checkpoint_path)\n",
        "        except:\n",
        "            # Fallback if loading fails\n",
        "            best_model = model\n",
        "\n",
        "        # Get predictions\n",
        "        y_pred_test = best_model.predict(X_test, verbose=0).flatten()\n",
        "\n",
        "        # Denormalize\n",
        "        y_test_actual = y_test * discharge_max\n",
        "        y_pred_test_actual = y_pred_test * discharge_max\n",
        "\n",
        "        # Calculate metrics\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test_actual, y_pred_test_actual))\n",
        "        relative_rmse = (test_rmse / discharge_max) * 100\n",
        "        test_r2 = r2_score(y_test_actual, y_pred_test_actual)\n",
        "\n",
        "        # Peak vs Non-peak analysis (threshold = 1500 as per paper)\n",
        "        threshold = 1500\n",
        "        peak_mask = y_test_actual > threshold\n",
        "        non_peak_mask = ~peak_mask\n",
        "\n",
        "        peak_rmse_rel = 0\n",
        "        non_peak_rmse_rel = 0\n",
        "\n",
        "        if peak_mask.sum() > 0:\n",
        "            peak_rmse = np.sqrt(mean_squared_error(\n",
        "                y_test_actual[peak_mask],\n",
        "                y_pred_test_actual[peak_mask]\n",
        "            ))\n",
        "            peak_rmse_rel = (peak_rmse / discharge_max) * 100\n",
        "\n",
        "        if non_peak_mask.sum() > 0:\n",
        "            non_peak_rmse = np.sqrt(mean_squared_error(\n",
        "                y_test_actual[non_peak_mask],\n",
        "                y_pred_test_actual[non_peak_mask]\n",
        "            ))\n",
        "            non_peak_rmse_rel = (non_peak_rmse / discharge_max) * 100\n",
        "\n",
        "        print(f\"‚Üí RMSE: {relative_rmse:.2f}%\")\n",
        "\n",
        "        # Store results\n",
        "        results_standard.append({\n",
        "            'Lag_Precip': lag_precip,\n",
        "            'Lag_Discharge': lag_discharge,\n",
        "            'Hidden_Size': hidden_size,\n",
        "            'Test_RMSE': test_rmse,\n",
        "            'Relative_RMSE': relative_rmse,\n",
        "            'Test_R2': test_r2,\n",
        "            'Peak_RMSE_Relative': peak_rmse_rel,\n",
        "            'NonPeak_RMSE_Relative': non_peak_rmse_rel,\n",
        "            'y_pred_test': y_pred_test_actual,\n",
        "            'y_test': y_test_actual,\n",
        "            'test_indices': test_idx,\n",
        "            'dates': df['datetime'].iloc[test_idx].values,\n",
        "            'best_epoch': np.argmin(history.history['val_loss']) + 1\n",
        "        })\n",
        "\n",
        "        # Clean up checkpoint file\n",
        "        try:\n",
        "            if os.path.exists(checkpoint_path):\n",
        "                os.remove(checkpoint_path)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"Training LSTM Models...\")\n",
        "print(\"-\"*60)\n",
        "print(\"Key changes:\")\n",
        "print(\"  ‚Ä¢ Using Adam optimizer (lr=0.001) as per paper for LSTM\")\n",
        "print(\"  ‚Ä¢ Training for FULL 200 epochs\")\n",
        "print(\"  ‚Ä¢ Using .keras format to avoid warnings\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "model_count = 0\n",
        "total_models_lstm = len(lag_combinations_lstm) * len(hidden_sizes)\n",
        "\n",
        "for lag, _ in lag_combinations_lstm:\n",
        "    print(f\"\\nLag config: m=n={lag}\")\n",
        "\n",
        "    # Create LSTM data: (samples, timesteps=lag, features=2)\n",
        "    max_lag = lag\n",
        "    n_samples = len(precip_normalized) - max_lag\n",
        "\n",
        "    X_lstm = np.zeros((n_samples, max_lag, 2))\n",
        "    y_lstm = np.zeros(n_samples)\n",
        "\n",
        "    for i in range(max_lag, len(precip_normalized)):\n",
        "        for t in range(max_lag):\n",
        "            X_lstm[i - max_lag, t, 0] = precip_normalized[i - (max_lag - t)]\n",
        "            X_lstm[i - max_lag, t, 1] = discharge_normalized[i - (max_lag - t)]\n",
        "        y_lstm[i - max_lag] = discharge_normalized[i]\n",
        "\n",
        "    valid_indices = np.arange(max_lag, len(precip_normalized))\n",
        "\n",
        "    # Split\n",
        "    split_idx = int(len(X_lstm) * train_ratio)\n",
        "    X_train_lstm = X_lstm[:split_idx]\n",
        "    X_test_lstm = X_lstm[split_idx:]\n",
        "    y_train_lstm = y_lstm[:split_idx]\n",
        "    y_test_lstm = y_lstm[split_idx:]\n",
        "    test_idx = valid_indices[split_idx:]\n",
        "\n",
        "    for hidden_size in hidden_sizes:\n",
        "        model_count += 1\n",
        "        print(f\"  [{model_count}/{total_models_lstm}] Hidden={hidden_size}\", end=\" \", flush=True)\n",
        "\n",
        "        # Build LSTM model\n",
        "        model = build_lstm_model(sequence_length=max_lag, hidden_size=hidden_size)\n",
        "\n",
        "        # Compile with Adam (lr=0.001 as per paper for LSTM)\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=0.001),\n",
        "            loss='mse',\n",
        "            metrics=['mae']\n",
        "        )\n",
        "\n",
        "        # Save best model checkpoint (using .keras format)\n",
        "        checkpoint_path = f'temp_models/lstm_lag{lag}_h{hidden_size}.keras'\n",
        "        checkpoint = ModelCheckpoint(\n",
        "            checkpoint_path,\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            mode='min',\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Train for full 200 epochs\n",
        "        history = model.fit(\n",
        "            X_train_lstm, y_train_lstm,\n",
        "            validation_data=(X_test_lstm, y_test_lstm),\n",
        "            epochs=200,\n",
        "            batch_size=32,\n",
        "            callbacks=[checkpoint],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Load best model\n",
        "        try:\n",
        "            best_model = keras.models.load_model(checkpoint_path)\n",
        "        except:\n",
        "            # Fallback if loading fails\n",
        "            best_model = model\n",
        "\n",
        "        # Predictions\n",
        "        y_pred_test = best_model.predict(X_test_lstm, verbose=0).flatten()\n",
        "\n",
        "        # Denormalize\n",
        "        y_test_actual = y_test_lstm * discharge_max\n",
        "        y_pred_test_actual = y_pred_test * discharge_max\n",
        "\n",
        "        # Calculate metrics\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test_actual, y_pred_test_actual))\n",
        "        relative_rmse = (test_rmse / discharge_max) * 100\n",
        "        test_r2 = r2_score(y_test_actual, y_pred_test_actual)\n",
        "\n",
        "        # Peak analysis\n",
        "        threshold = 1500\n",
        "        peak_mask = y_test_actual > threshold\n",
        "        non_peak_mask = ~peak_mask\n",
        "\n",
        "        peak_rmse_rel = 0\n",
        "        non_peak_rmse_rel = 0\n",
        "\n",
        "        if peak_mask.sum() > 0:\n",
        "            peak_rmse = np.sqrt(mean_squared_error(\n",
        "                y_test_actual[peak_mask],\n",
        "                y_pred_test_actual[peak_mask]\n",
        "            ))\n",
        "            peak_rmse_rel = (peak_rmse / discharge_max) * 100\n",
        "\n",
        "        if non_peak_mask.sum() > 0:\n",
        "            non_peak_rmse = np.sqrt(mean_squared_error(\n",
        "                y_test_actual[non_peak_mask],\n",
        "                y_pred_test_actual[non_peak_mask]\n",
        "            ))\n",
        "            non_peak_rmse_rel = (non_peak_rmse / discharge_max) * 100\n",
        "\n",
        "        print(f\"‚Üí RMSE: {relative_rmse:.2f}%\")\n",
        "\n",
        "        # Store results\n",
        "        results_lstm.append({\n",
        "            'Lag_Precip': lag,\n",
        "            'Lag_Discharge': lag,\n",
        "            'Hidden_Size': hidden_size,\n",
        "            'Test_RMSE': test_rmse,\n",
        "            'Relative_RMSE': relative_rmse,\n",
        "            'Test_R2': test_r2,\n",
        "            'Peak_RMSE_Relative': peak_rmse_rel,\n",
        "            'NonPeak_RMSE_Relative': non_peak_rmse_rel,\n",
        "            'y_pred_test': y_pred_test_actual,\n",
        "            'y_test': y_test_actual,\n",
        "            'test_indices': test_idx,\n",
        "            'dates': df['datetime'].iloc[test_idx].values,\n",
        "            'best_epoch': np.argmin(history.history['val_loss']) + 1\n",
        "        })\n",
        "\n",
        "        # Clean up\n",
        "        try:\n",
        "            if os.path.exists(checkpoint_path):\n",
        "                os.remove(checkpoint_path)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# Clean up temp directory\n",
        "try:\n",
        "    if os.path.exists('temp_models') and not os.listdir('temp_models'):\n",
        "        os.rmdir('temp_models')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Convert to DataFrames\n",
        "results_standard_df = pd.DataFrame(results_standard)\n",
        "results_lstm_df = pd.DataFrame(results_lstm)\n",
        "\n",
        "# Find best models\n",
        "best_standard = results_standard_df.loc[results_standard_df['Relative_RMSE'].idxmin()]\n",
        "best_lstm = results_lstm_df.loc[results_lstm_df['Relative_RMSE'].idxmin()]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BEST MODELS FOUND\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nüèÜ Best Standard NN:\")\n",
        "print(f\"   Lag Precip (m): {best_standard['Lag_Precip']}\")\n",
        "print(f\"   Lag Discharge (n): {best_standard['Lag_Discharge']}\")\n",
        "print(f\"   Hidden Size: {best_standard['Hidden_Size']}\")\n",
        "print(f\"   Overall RMSE: {best_standard['Relative_RMSE']:.2f}%\")\n",
        "print(f\"   Peak RMSE: {best_standard['Peak_RMSE_Relative']:.2f}%\")\n",
        "print(f\"   Non-Peak RMSE: {best_standard['NonPeak_RMSE_Relative']:.2f}%\")\n",
        "print(f\"   R¬≤ Score: {best_standard['Test_R2']:.4f}\")\n",
        "print(f\"   Best Epoch: {best_standard['best_epoch']}\")\n",
        "\n",
        "print(f\"\\nüèÜ Best LSTM:\")\n",
        "print(f\"   Lag (m=n): {best_lstm['Lag_Precip']}\")\n",
        "print(f\"   Hidden Size: {best_lstm['Hidden_Size']}\")\n",
        "print(f\"   Overall RMSE: {best_lstm['Relative_RMSE']:.2f}%\")\n",
        "print(f\"   Peak RMSE: {best_lstm['Peak_RMSE_Relative']:.2f}%\")\n",
        "print(f\"   Non-Peak RMSE: {best_lstm['NonPeak_RMSE_Relative']:.2f}%\")\n",
        "print(f\"   R¬≤ Score: {best_lstm['Test_R2']:.4f}\")\n",
        "print(f\"   Best Epoch: {best_lstm['best_epoch']}\")\n",
        "\n",
        "print(f\"\\nüìä Paper's Best Results for Comparison:\")\n",
        "print(f\"   Standard NN: Overall=0.23%, Peak=0.63%, Non-Peak=0.07%\")\n",
        "print(f\"   LSTM: Overall=2.43%, Peak=6.78%, Non-Peak=0.54%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcQ_7b4Gyksb",
        "outputId": "91ffd478-d7de-450d-b987-a56823928cbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 7: Generating Table 1 (RMSE Summary)\n",
            "============================================================\n",
            "\n",
            "RMSE on validation Standard  LSTM\n",
            "          at peaks   10.26% 6.88%\n",
            "      at non-peaks    1.78% 1.10%\n",
            "           overall    4.21% 2.79%\n",
            "\n",
            "‚úì Saved: table1_rmse_summary.csv\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 7: Generating Table 1 (RMSE Summary)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "table_data = {\n",
        "    'RMSE on validation': ['at peaks', 'at non-peaks', 'overall'],\n",
        "    'Standard': [\n",
        "        f\"{best_standard['Peak_RMSE_Relative']:.2f}%\",\n",
        "        f\"{best_standard['NonPeak_RMSE_Relative']:.2f}%\",\n",
        "        f\"{best_standard['Relative_RMSE']:.2f}%\"\n",
        "    ],\n",
        "    'LSTM': [\n",
        "        f\"{best_lstm['Peak_RMSE_Relative']:.2f}%\",\n",
        "        f\"{best_lstm['NonPeak_RMSE_Relative']:.2f}%\",\n",
        "        f\"{best_lstm['Relative_RMSE']:.2f}%\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "table_df = pd.DataFrame(table_data)\n",
        "print(\"\\n\" + table_df.to_string(index=False))\n",
        "\n",
        "table_df.to_csv('table1_rmse_summary.csv', index=False)\n",
        "print(\"\\n‚úì Saved: table1_rmse_summary.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04NDb5-azX6z",
        "outputId": "b22d4190-7343-4a69-b17d-12a5143cccf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 8: Generating Figure 3 - Best Standard NN\n",
            "============================================================\n",
            "‚úì Saved: figure3_best_standard_nn.png\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 8: Generating Figure 3 - Best Standard NN\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "dates = best_standard['dates']\n",
        "actual = best_standard['y_test']\n",
        "pred = best_standard['y_pred_test']\n",
        "\n",
        "ax.plot(dates, actual, 'b-', label='Actual', linewidth=2, alpha=0.7)\n",
        "ax.plot(dates, pred, 'r--', label='Predicted', linewidth=2, alpha=0.8)\n",
        "ax.set_xlabel('Date', fontsize=12)\n",
        "ax.set_ylabel('Discharge (ft¬≥/s)', fontsize=12)\n",
        "ax.set_title(f'Figure 3. Best model of Standard feed-forward\\n(m={best_standard[\"Lag_Precip\"]}, n={best_standard[\"Lag_Discharge\"]}, hidden={best_standard[\"Hidden_Size\"]}, RMSE={best_standard[\"Relative_RMSE\"]:.2f}%)', fontsize=13)\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig('figure3_best_standard_nn.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: figure3_best_standard_nn.png\")\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktpe0-bGzc8G",
        "outputId": "941f581d-73b7-4dcd-88df-053faededaaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 9: Generating Figure 4 - Best LSTM\n",
            "============================================================\n",
            "‚úì Saved: figure4_best_lstm.png\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 9: Generating Figure 4 - Best LSTM\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "dates = best_lstm['dates']\n",
        "actual = best_lstm['y_test']\n",
        "pred = best_lstm['y_pred_test']\n",
        "\n",
        "ax.plot(dates, actual, 'b-', label='Actual', linewidth=2, alpha=0.7)\n",
        "ax.plot(dates, pred, 'r--', label='Predicted', linewidth=2, alpha=0.8)\n",
        "ax.set_xlabel('Date', fontsize=12)\n",
        "ax.set_ylabel('Discharge (ft¬≥/s)', fontsize=12)\n",
        "ax.set_title(f'Figure 4. Best model of LSTM\\n(m=n={best_lstm[\"Lag_Precip\"]}, hidden={best_lstm[\"Hidden_Size\"]}, RMSE={best_lstm[\"Relative_RMSE\"]:.2f}%)', fontsize=13)\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig('figure4_best_lstm.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: figure4_best_lstm.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46c9PWHDzhNp",
        "outputId": "8f962d20-3c27-4386-b014-eecdba8f58f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 10: Generating Figures 5-7 - RMSE Variation (Standard NN)\n",
            "============================================================\n",
            "‚úì Saved: figure5_rmse_standard_diff1.png\n",
            "‚úì Saved: figure6_rmse_standard_diff2.png\n",
            "‚úì Saved: figure7_rmse_standard_diff3.png\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 10: Generating Figures 5-7 - RMSE Variation (Standard NN)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Group by n-m difference\n",
        "diff_groups = {1: [], 2: [], 3: []}\n",
        "for _, row in results_standard_df.iterrows():\n",
        "    diff = row['Lag_Discharge'] - row['Lag_Precip']\n",
        "    if diff in diff_groups:\n",
        "        diff_groups[diff].append(row.to_dict())\n",
        "\n",
        "fig_count = 5\n",
        "for diff, group_list in sorted(diff_groups.items()):\n",
        "    if not group_list:\n",
        "        continue\n",
        "\n",
        "    group_df = pd.DataFrame(group_list)\n",
        "    unique_m = sorted(group_df['Lag_Precip'].unique())\n",
        "\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(10, 12))\n",
        "\n",
        "    metrics = [\n",
        "        ('Relative_RMSE', axes[0], f'Overall RMSE (n-m={diff})'),\n",
        "        ('Peak_RMSE_Relative', axes[1], f'RMSE at peaks (n-m={diff})'),\n",
        "        ('NonPeak_RMSE_Relative', axes[2], f'RMSE at non-peaks (n-m={diff})')\n",
        "    ]\n",
        "\n",
        "    colors = ['blue', 'green', 'red', 'orange', 'purple', 'brown']\n",
        "\n",
        "    for col, ax, title in metrics:\n",
        "        for i, m in enumerate(unique_m):\n",
        "            subset = group_df[group_df['Lag_Precip'] == m].sort_values('Hidden_Size')\n",
        "            if len(subset) > 0:\n",
        "                ax.plot(subset['Hidden_Size'], subset[col],\n",
        "                       marker='o', label=f'm={m}',\n",
        "                       color=colors[i % len(colors)], linewidth=2)\n",
        "\n",
        "        ax.set_xlabel('Hidden size', fontsize=11)\n",
        "        ax.set_ylabel('RMSE relative to max flow (%)', fontsize=11)\n",
        "        ax.set_title(title, fontsize=12)\n",
        "        ax.legend(fontsize=10)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle(f'Figure {fig_count}. RMSE variation for the standard NN with n-m={diff}',\n",
        "                 fontsize=14, y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'figure{fig_count}_rmse_standard_diff{diff}.png', dpi=300, bbox_inches='tight')\n",
        "    print(f\"‚úì Saved: figure{fig_count}_rmse_standard_diff{diff}.png\")\n",
        "    plt.close()\n",
        "    fig_count += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ect_cywvzm1x",
        "outputId": "4cafd8b0-a4f5-4fc5-84ab-b16a8ac1ef23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 11: Generating Figure 8 - RMSE Variation (LSTM)\n",
            "============================================================\n",
            "‚úì Saved: figure8_rmse_lstm.png\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 11: Generating Figure 8 - RMSE Variation (LSTM)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "unique_lags = sorted(results_lstm_df['Lag_Precip'].unique())\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(10, 12))\n",
        "\n",
        "metrics = [\n",
        "    ('Relative_RMSE', axes[0], 'Overall RMSE'),\n",
        "    ('Peak_RMSE_Relative', axes[1], 'RMSE at peaks'),\n",
        "    ('NonPeak_RMSE_Relative', axes[2], 'RMSE at non-peaks')\n",
        "]\n",
        "\n",
        "colors = ['blue', 'green', 'red', 'orange', 'purple', 'brown']\n",
        "\n",
        "for col, ax, title in metrics:\n",
        "    for i, lag in enumerate(unique_lags):\n",
        "        subset = results_lstm_df[results_lstm_df['Lag_Precip'] == lag].sort_values('Hidden_Size')\n",
        "        if len(subset) > 0:\n",
        "            ax.plot(subset['Hidden_Size'], subset[col],\n",
        "                   marker='o', label=f'm=n={lag}',\n",
        "                   color=colors[i % len(colors)], linewidth=2)\n",
        "\n",
        "    ax.set_xlabel('Hidden size', fontsize=11)\n",
        "    ax.set_ylabel('RMSE relative to max flow (%)', fontsize=11)\n",
        "    ax.set_title(title, fontsize=12)\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Figure 8. RMSE variation for the LSTM network', fontsize=14, y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.savefig('figure8_rmse_lstm.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: figure8_rmse_lstm.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5wObbswzn9F",
        "outputId": "8ca177bc-4379-4c38-ed13-c92980eccb9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 12: Saving Detailed Results\n",
            "============================================================\n",
            "‚úì Saved: detailed_results_standard_nn.csv\n",
            "‚úì Saved: detailed_results_lstm.csv\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 12: Saving Detailed Results\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save all results to CSV for further analysis\n",
        "results_standard_summary = results_standard_df[[\n",
        "    'Lag_Precip', 'Lag_Discharge', 'Hidden_Size',\n",
        "    'Relative_RMSE', 'Peak_RMSE_Relative', 'NonPeak_RMSE_Relative',\n",
        "    'Test_R2', 'best_epoch'\n",
        "]].copy()\n",
        "\n",
        "results_lstm_summary = results_lstm_df[[\n",
        "    'Lag_Precip', 'Lag_Discharge', 'Hidden_Size',\n",
        "    'Relative_RMSE', 'Peak_RMSE_Relative', 'NonPeak_RMSE_Relative',\n",
        "    'Test_R2', 'best_epoch'\n",
        "]].copy()\n",
        "\n",
        "results_standard_summary.to_csv('detailed_results_standard_nn.csv', index=False)\n",
        "results_lstm_summary.to_csv('detailed_results_lstm.csv', index=False)\n",
        "\n",
        "print(\"‚úì Saved: detailed_results_standard_nn.csv\")\n",
        "print(\"‚úì Saved: detailed_results_lstm.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhaDw4PGzsPZ",
        "outputId": "e6a725b1-30fd-4f3a-86ff-12de30040073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "IMPLEMENTATION COMPLETE! ‚úì\n",
            "================================================================================\n",
            "\n",
            "üìÅ Generated Outputs:\n",
            "   1. table1_rmse_summary.csv - Table 1: RMSE comparison\n",
            "   2. figure3_best_standard_nn.png - Best Standard NN predictions\n",
            "   3. figure4_best_lstm.png - Best LSTM predictions\n",
            "   4. figure5_rmse_standard_diff1.png - RMSE variation (n-m=1)\n",
            "   5. figure6_rmse_standard_diff2.png - RMSE variation (n-m=2)\n",
            "   6. figure7_rmse_standard_diff3.png - RMSE variation (n-m=3)\n",
            "   7. figure8_rmse_lstm.png - RMSE variation for LSTM\n",
            "   8. detailed_results_standard_nn.csv - All Standard NN results\n",
            "   9. detailed_results_lstm.csv - All LSTM results\n",
            "\n",
            "üîç Diagnostic Information:\n",
            "   Total Standard NN models trained: 84\n",
            "   Total LSTM models trained: 42\n",
            "   Average epochs to convergence (Standard NN): 200.0\n",
            "   Average epochs to convergence (LSTM): 78.5\n",
            "\n",
            "üìä Performance Comparison with Paper:\n",
            "\n",
            "   Standard NN:\n",
            "      Your results  ‚Üí Overall: 4.21%, Peak: 10.26%, Non-Peak: 1.78%\n",
            "      Paper results ‚Üí Overall: 0.23%, Peak: 0.63%, Non-Peak: 0.07%\n",
            "      Ratio         ‚Üí Overall: 18.3x, Peak: 16.3x, Non-Peak: 25.5x\n",
            "\n",
            "   LSTM:\n",
            "      Your results  ‚Üí Overall: 2.79%, Peak: 6.88%, Non-Peak: 1.10%\n",
            "      Paper results ‚Üí Overall: 2.43%, Peak: 6.78%, Non-Peak: 0.54%\n",
            "      Ratio         ‚Üí Overall: 1.15x, Peak: 1.01x, Non-Peak: 2.04x\n",
            "\n",
            "üí° Key Improvements Applied:\n",
            "   ‚úì Removed early stopping - all models train for full 200 epochs\n",
            "   ‚úì Using SGD optimizer for Standard NN (lr=0.009)\n",
            "   ‚úì Using Adam optimizer for LSTM (lr=0.001)\n",
            "   ‚úì Proper best model selection via ModelCheckpoint\n",
            "   ‚úì Correct activation functions (sigmoid hidden, linear output)\n",
            "   ‚úì Peak threshold applied to denormalized values (1500 ft¬≥/s)\n",
            "\n",
            "‚ö†Ô∏è If results still differ significantly from paper:\n",
            "   1. Check if your discharge_max matches paper's 29,700 ft¬≥/s\n",
            "   2. Check if your precipitation_max matches paper's 6.8 inches\n",
            "   3. Verify data comes from Leaf River Basin near Collins, LA\n",
            "   4. Ensure time period is similar (paper: 2003-2012)\n",
            "   5. Consider that paper may have used different preprocessing\n",
            "   6. Random initialization may cause slight variations\n",
            "\n",
            "üéØ Next Steps:\n",
            "   ‚Ä¢ Review the generated figures to visually assess predictions\n",
            "   ‚Ä¢ Compare RMSE patterns with paper's Figures 5-8\n",
            "   ‚Ä¢ If Standard NN still underperforms, try:\n",
            "     - Different batch sizes (try 16 or 64)\n",
            "     - Different random seeds\n",
            "     - Verify normalization is correct\n",
            "     - Check for data quality issues\n",
            "\n",
            "================================================================================\n",
            "END OF IMPLEMENTATION\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"IMPLEMENTATION COMPLETE! ‚úì\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nüìÅ Generated Outputs:\")\n",
        "print(f\"   1. table1_rmse_summary.csv - Table 1: RMSE comparison\")\n",
        "print(f\"   2. figure3_best_standard_nn.png - Best Standard NN predictions\")\n",
        "print(f\"   3. figure4_best_lstm.png - Best LSTM predictions\")\n",
        "print(f\"   4. figure5_rmse_standard_diff1.png - RMSE variation (n-m=1)\")\n",
        "print(f\"   5. figure6_rmse_standard_diff2.png - RMSE variation (n-m=2)\")\n",
        "print(f\"   6. figure7_rmse_standard_diff3.png - RMSE variation (n-m=3)\")\n",
        "print(f\"   7. figure8_rmse_lstm.png - RMSE variation for LSTM\")\n",
        "print(f\"   8. detailed_results_standard_nn.csv - All Standard NN results\")\n",
        "print(f\"   9. detailed_results_lstm.csv - All LSTM results\")\n",
        "\n",
        "print(f\"\\nüîç Diagnostic Information:\")\n",
        "print(f\"   Total Standard NN models trained: {len(results_standard_df)}\")\n",
        "print(f\"   Total LSTM models trained: {len(results_lstm_df)}\")\n",
        "print(f\"   Average epochs to convergence (Standard NN): {results_standard_df['best_epoch'].mean():.1f}\")\n",
        "print(f\"   Average epochs to convergence (LSTM): {results_lstm_df['best_epoch'].mean():.1f}\")\n",
        "\n",
        "print(f\"\\nüìä Performance Comparison with Paper:\")\n",
        "print(f\"\\n   Standard NN:\")\n",
        "print(f\"      Your results  ‚Üí Overall: {best_standard['Relative_RMSE']:.2f}%, Peak: {best_standard['Peak_RMSE_Relative']:.2f}%, Non-Peak: {best_standard['NonPeak_RMSE_Relative']:.2f}%\")\n",
        "print(f\"      Paper results ‚Üí Overall: 0.23%, Peak: 0.63%, Non-Peak: 0.07%\")\n",
        "print(f\"      Ratio         ‚Üí Overall: {best_standard['Relative_RMSE']/0.23:.1f}x, Peak: {best_standard['Peak_RMSE_Relative']/0.63:.1f}x, Non-Peak: {best_standard['NonPeak_RMSE_Relative']/0.07:.1f}x\")\n",
        "\n",
        "print(f\"\\n   LSTM:\")\n",
        "print(f\"      Your results  ‚Üí Overall: {best_lstm['Relative_RMSE']:.2f}%, Peak: {best_lstm['Peak_RMSE_Relative']:.2f}%, Non-Peak: {best_lstm['NonPeak_RMSE_Relative']:.2f}%\")\n",
        "print(f\"      Paper results ‚Üí Overall: 2.43%, Peak: 6.78%, Non-Peak: 0.54%\")\n",
        "print(f\"      Ratio         ‚Üí Overall: {best_lstm['Relative_RMSE']/2.43:.2f}x, Peak: {best_lstm['Peak_RMSE_Relative']/6.78:.2f}x, Non-Peak: {best_lstm['NonPeak_RMSE_Relative']/0.54:.2f}x\")\n",
        "\n",
        "print(f\"\\nüí° Key Improvements Applied:\")\n",
        "print(f\"   ‚úì Removed early stopping - all models train for full 200 epochs\")\n",
        "print(f\"   ‚úì Using SGD optimizer for Standard NN (lr=0.009)\")\n",
        "print(f\"   ‚úì Using Adam optimizer for LSTM (lr=0.001)\")\n",
        "print(f\"   ‚úì Proper best model selection via ModelCheckpoint\")\n",
        "print(f\"   ‚úì Correct activation functions (sigmoid hidden, linear output)\")\n",
        "print(f\"   ‚úì Peak threshold applied to denormalized values (1500 ft¬≥/s)\")\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è If results still differ significantly from paper:\")\n",
        "print(f\"   1. Check if your discharge_max matches paper's 29,700 ft¬≥/s\")\n",
        "print(f\"   2. Check if your precipitation_max matches paper's 6.8 inches\")\n",
        "print(f\"   3. Verify data comes from Leaf River Basin near Collins, LA\")\n",
        "print(f\"   4. Ensure time period is similar (paper: 2003-2012)\")\n",
        "print(f\"   5. Consider that paper may have used different preprocessing\")\n",
        "print(f\"   6. Random initialization may cause slight variations\")\n",
        "\n",
        "print(f\"\\nüéØ Next Steps:\")\n",
        "print(f\"   ‚Ä¢ Review the generated figures to visually assess predictions\")\n",
        "print(f\"   ‚Ä¢ Compare RMSE patterns with paper's Figures 5-8\")\n",
        "print(f\"   ‚Ä¢ If Standard NN still underperforms, try:\")\n",
        "print(f\"     - Different batch sizes (try 16 or 64)\")\n",
        "print(f\"     - Different random seeds\")\n",
        "print(f\"     - Verify normalization is correct\")\n",
        "print(f\"     - Check for data quality issues\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"END OF IMPLEMENTATION\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
